{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "I want to build a chatbot application that can answer questions related to rap star Eminem . But the LLM model (gpt-3.5-turbo-instruct) finished training in Sep 2021 and it does not have the up-to-date information (especially things happened last year). Therefore I need to use RAG to provide up-to-date information in the custom query before sending to LLM.\n",
    "\n",
    "I want to choose Eminem wikipedia page as the data source. Because the web page has rich and factual content covering most of the related questions. Since the content is in a webpage, I will use requests + BeautifulSoup to prepare the data (requests + BeautifulSoup)\n",
    "\n",
    "Wikipedia source: https://en.wikipedia.org/wiki/Eminem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "594992c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare environment variable\n",
    "# Environment variables\n",
    "OPENAI_API_KEY = 'YOU_API_KEY\n",
    "\n",
    "# URLs and file paths\n",
    "SOURCE_URL = 'https://en.wikipedia.org/wiki/Eminem'\n",
    "CSV_FILEPATH_WITH_EMBEDDINGS = './eminem_embeddings.csv'\n",
    "\n",
    "# OpenAI Models\n",
    "EMBEDDING_MODEL = 'text-embedding-ada-002'\n",
    "COMPLETION_MODEL = 'gpt-3.5-turbo-instruct'\n",
    "\n",
    "# Batch size for processing\n",
    "BATCH_SIZE = 25\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "TODO: In the cells below, load your chosen dataset into a `pandas` dataframe with a column named `\"text\"`. This column should contain all of your text data, separated into at least 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a GET request\n",
    "response = requests.get(SOURCE_URL)\n",
    "\n",
    "# print the status code\n",
    "# print(response.status_code)\n",
    "\n",
    "# print the content of the response\n",
    "# print(response.content)\n",
    "\n",
    "with open(\"mount_everest.html\", mode='wb') as file:\n",
    "    file.write(response.content)\n",
    "    \n",
    "with open(\"mount_everest.html\") as fp:\n",
    "    mount_everest_content = BeautifulSoup(fp, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0a595980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marshall Bruce Mathers III (born October 17, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After the release of his debut album Infinite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eminem was also a member of the hip-hop groups...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eminem is among the best-selling music artists...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marshall Bruce Mathers III was born on October...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Eminem has also been included and ranked in se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Solo studio albums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>D12 studio albums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>As a headliner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>As a co-headliner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   Marshall Bruce Mathers III (born October 17, 1...\n",
       "1   After the release of his debut album Infinite ...\n",
       "2   Eminem was also a member of the hip-hop groups...\n",
       "3   Eminem is among the best-selling music artists...\n",
       "4   Marshall Bruce Mathers III was born on October...\n",
       "..                                                ...\n",
       "89  Eminem has also been included and ranked in se...\n",
       "90                                 Solo studio albums\n",
       "91                                  D12 studio albums\n",
       "92                                     As a headliner\n",
       "93                                  As a co-headliner\n",
       "\n",
       "[94 rows x 1 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = [item.text.strip() for item in mount_everest_content.find_all('p')]\n",
    "items = list(filter(lambda item: (len(item) != 0), items))\n",
    "df = pd.DataFrame()\n",
    "df['text'] = items\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb3a9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "TODO: In the cells below, compose a custom query using your chosen dataset and retrieve results from an OpenAI `Completion` model. You may copy and paste any useful code from the course materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "582f0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API creds\n",
    "import openai\n",
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marshall Bruce Mathers III (born October 17, 1...</td>\n",
       "      <td>[-0.032345566898584366, -0.026841014623641968,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After the release of his debut album Infinite ...</td>\n",
       "      <td>[-0.015536091290414333, -0.019841734319925308,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eminem was also a member of the hip-hop groups...</td>\n",
       "      <td>[-0.01941017061471939, -0.04326850548386574, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eminem is among the best-selling music artists...</td>\n",
       "      <td>[-0.029969148337841034, -0.030934298411011696,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marshall Bruce Mathers III was born on October...</td>\n",
       "      <td>[-0.02432360127568245, -0.026493549346923828, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Eminem has also been included and ranked in se...</td>\n",
       "      <td>[-0.026019081473350525, -0.029423678293824196,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Solo studio albums</td>\n",
       "      <td>[-0.027343137189745903, -0.017208876088261604,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>D12 studio albums</td>\n",
       "      <td>[-0.020676232874393463, -0.01961451768875122, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>As a headliner</td>\n",
       "      <td>[-0.018161434680223465, -0.005976084619760513,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>As a co-headliner</td>\n",
       "      <td>[-0.017501680180430412, -0.015271073207259178,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   Marshall Bruce Mathers III (born October 17, 1...   \n",
       "1   After the release of his debut album Infinite ...   \n",
       "2   Eminem was also a member of the hip-hop groups...   \n",
       "3   Eminem is among the best-selling music artists...   \n",
       "4   Marshall Bruce Mathers III was born on October...   \n",
       "..                                                ...   \n",
       "89  Eminem has also been included and ranked in se...   \n",
       "90                                 Solo studio albums   \n",
       "91                                  D12 studio albums   \n",
       "92                                     As a headliner   \n",
       "93                                  As a co-headliner   \n",
       "\n",
       "                                           embeddings  \n",
       "0   [-0.032345566898584366, -0.026841014623641968,...  \n",
       "1   [-0.015536091290414333, -0.019841734319925308,...  \n",
       "2   [-0.01941017061471939, -0.04326850548386574, -...  \n",
       "3   [-0.029969148337841034, -0.030934298411011696,...  \n",
       "4   [-0.02432360127568245, -0.026493549346923828, ...  \n",
       "..                                                ...  \n",
       "89  [-0.026019081473350525, -0.029423678293824196,...  \n",
       "90  [-0.027343137189745903, -0.017208876088261604,...  \n",
       "91  [-0.020676232874393463, -0.01961451768875122, ...  \n",
       "92  [-0.018161434680223465, -0.005976084619760513,...  \n",
       "93  [-0.017501680180430412, -0.015271073207259178,...  \n",
       "\n",
       "[94 rows x 2 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "embeddings = []\n",
    "for i in range(0, len(df), batch_size):\n",
    "    # Send text data to OpenAI model to get embeddings\n",
    "    response = openai.Embedding.create(\n",
    "        input=df.iloc[i:i+batch_size][\"text\"].tolist(),\n",
    "        engine=EMBEDDING_MODEL\n",
    "    )\n",
    "    \n",
    "    embeddings.extend([data['embedding'] for data in response['data']])\n",
    "\n",
    "df['embeddings'] = embeddings\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "13f2dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(CSV_FILEPATH_WITH_EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c403f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer as well as prompt template\n",
    "# question - original user prompt\n",
    "# df - sorted data frame by ascending distance\n",
    "# max_token_count - max allowed tokens to send to OpenAI\n",
    "import tiktoken\n",
    "def create_prompt(question, df, max_token_count):\n",
    "    \"\"\"\n",
    "    Given a question and a dataframe containing rows of text and their\n",
    "    embeddings, return a text prompt to send to a Completion model\n",
    "    \"\"\"\n",
    "    # Create a tokenizer that is designed to align with our embeddings\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    # Count the number of tokens in the prompt template and question\n",
    "    prompt_template = \"\"\"\n",
    "        Answer the question based on the context below, and if the question\n",
    "        can't be answered based on the context, say \"I don't know\"\n",
    "\n",
    "        Context: \n",
    "\n",
    "        {}\n",
    "\n",
    "        ---\n",
    "\n",
    "        Question: {}\n",
    "        Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    if df is None:\n",
    "        return prompt_template.format('No context', question)\n",
    "    \n",
    "    print(f\"Question has this many tokens: {len(tokenizer.encode(question))}\")\n",
    "    print(f\"Prompt template has this many tokens: {len(tokenizer.encode(prompt_template))}\")\n",
    "    remaining_token_count = max_token_count - len(tokenizer.encode(question)) - len(tokenizer.encode(prompt_template))\n",
    "    print(f\"Remaining token count is: {remaining_token_count}\")\n",
    "    text_ary = []\n",
    "    for text in df['text'].tolist():\n",
    "        if remaining_token_count > len(tokenizer.encode(text)):\n",
    "            remaining_token_count = remaining_token_count - len(tokenizer.encode(text))\n",
    "            text_ary.append(text)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    context = \"\\n\\n###\\n\\n\".join(text_ary)\n",
    "    return prompt_template.format(context, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "74280b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding\n",
    "from openai.embeddings_utils import distances_from_embeddings\n",
    "\n",
    "def sort_df_by_asc_distance(q, df):\n",
    "    q_embedding = get_embedding(q, engine=EMBEDDING_MODEL)\n",
    "    distances = distances_from_embeddings(q_embedding, df['embeddings'].tolist(), distance_metric='cosine')\n",
    "    df['distances'] = distances\n",
    "    return df.sort_values(by='distances')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c19d909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def get_response_from_openai(q, df, use_template):\n",
    "    if not use_template:\n",
    "        return openai.Completion.create(model=COMPLETION_MODEL, prompt=q, max_tokens=2000)\n",
    "    if df is None:\n",
    "        custom_prompt = create_prompt(q, None, 1500)\n",
    "    else:\n",
    "        sorted_df = sort_df_by_asc_distance(q, df)\n",
    "        # print(sorted_df.head())\n",
    "        custom_prompt = create_prompt(q, sorted_df, 1500)\n",
    "        # print(custom_prompt)\n",
    "    return openai.Completion.create(model=COMPLETION_MODEL, prompt=custom_prompt, max_tokens=2000)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4901c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question has this many tokens: 27\n",
      "Prompt template has this many tokens: 50\n",
      "Remaining token count is: 1423\n",
      "#### With RAG, the response is #### \n",
      " \n",
      "        In July 2023. \n",
      "\n",
      "\n",
      "#### Without RAG, the response is #### \n",
      "  \n",
      "\n",
      "\n",
      "#### Without RAG without template, the response is #### \n",
      " \n",
      "Eminem's Shady Records did not sign Ez Mil in a direct joint deal with Aftermath Entertainment and Interscope Records. This information is not accurate and there is no evidence to support it. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_1 = '''What year did Eminem's Shady Records sign Ez Mil in a direct joint deal with Aftermath Entertainment and Interscope Records?'''\n",
    "response_1 = get_response_from_openai(q_1, df, True)\n",
    "response_2 = get_response_from_openai(q_1, None, True)\n",
    "response_3 = get_response_from_openai(q_1, None, False)\n",
    "# df\n",
    "print(f\"#### With RAG, the response is #### \\n {response_1['choices'][0]['text']} \\n\\n\")\n",
    "print(f\"#### Without RAG, the response is #### \\n {response_2['choices'][0]['text']} \\n\\n\")\n",
    "print(f\"#### Without RAG without template, the response is #### \\n {response_3['choices'][0]['text']} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a093b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6f646989",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_2 = '''What year did Eminem appear alongside Roger Goodell at the opening ceremony of the NFL draft in Detroit'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2_1 = get_response_from_openai(q_2, df, True)\n",
    "response_2_2 = get_response_from_openai(q_2, None, True)\n",
    "response_2_3 = get_response_from_openai(q_2, None, False)\n",
    "# df\n",
    "print(f\"#### With RAG, the response is #### \\n {response_2_1['choices'][0]['text']} \\n\\n\")\n",
    "print(f\"#### Without RAG, the response is #### \\n {response_2_2['choices'][0]['text']} \\n\\n\")\n",
    "print(f\"#### Without RAG without template, the response is #### \\n {response_2_3['choices'][0]['text']} \\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
